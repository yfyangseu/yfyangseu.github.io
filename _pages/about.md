---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a final-year Ph.D. candidate in Computer Science and Engineering at The Ohio State University, where I'm fortunately advised by Prof. [DeLiang Wang](https://pnlwang.github.io/). I have 5+ years of research experience in robust automatic speech recognition (ASR), source separation, and multi-channel speech modeling. I'm a former Research Scientist Intern at Meta, MERL, and MSR Asia, with a focus on multi-channel ASR, speech foundation models, and their application on wearables.

I'm looking for full-time research-oriented industry positions (Research Scientist / Research Engineer / Machine Learning Engineer) starting Summer 2026, with a preference for the Bay Area roles. Here is my [CV](https://drive.google.com/file/d/1i8gfEdywo-zE7iEZgqwhEvywzZ6SXTev/view?usp=sharing).

Feel free to contact me via email: [yang.5662@osu.edu](mailto:yang.5662@osu.edu) or [yfyang@ieee.org](mailto:yfyang@ieee.org).

Education
======
* **Ph.D.** in Computer Science and Engineering, The Ohio State University - Columbus, OH, 2026 (expected)
  * Advisor: Prof. DeLiang Wang
 
* **M.S.** in Electrical and Computer Engineering, Georgia Institute of Technology - Atlanta, GA, 2020
  * Advisor: Prof. David V Anderson
  
* **B.E.** in Information Engineering, Southeast University - Nanjing, China, 2018
  * Advisor: Prof. Chuan Zhang

Industry Experience
======
* Research Scientist Intern, Meta (May - August 2025)
  * Proposed multi-channel differential ASR for smart glasses, improving robustness of wearer speech recognition in real-world scenarios against side-talk
  * Integrated complementary frontends for on-device streaming ASR without increasing latency
  * Demonstrated that the proposed system outperforms the internal baseline with up to 18% relative WER reduction under streaming and on-device Bluetooth bandwidth constraints
  * Resulted in a first-authored paper under review
 
* Research Scientist Intern, Meta (May - August 2024)
  * Proposed M-BEST-RQ, a novel array-agnostic multi-channel speech foundation model for smart glasses
  * Demonstrated that the model trained on one device can work across different wearable devices on conversational ASR, source localization, and wearer VAD
  * With only 8 hours of labeled speech for fine-tuning, the proposed model achieves a 3% absolute WER reduction over a baseline trained on 2k hours of labeled data for conversational ASR, demonstrating strong label efficiency
  * Resulted in a first-authored paper accepted to ICASSP 2025
    
* Research Intern, Mitsubishi Electric Research Laboratories (May - August 2023)
  * Developed unsupervised source separation methods leveraging self-supervised learning representations for multi-talker scenarios
  * Evaluated separation quality and representation transfer across different acoustic conditions
    
* Research Intern, Microsoft Research Asia (May - August 2019)
  * Developed and evaluated models for overlapped speech detection and speaker separation in conversational scenarios


Selected Publications
======
1. **Yufeng Yang**, Yiteng Huang, Yong Xu, Li Wan, Suwon Shon, Yang Liu, Yifeng Fan, Zhaojun Yang, Olivier Siohan, Yue Liu, Ming Sun, and Florian Metze, "Multi-channel differential ASR for robust wearer speech recognition on smart glasses," _arXiv:2509.14430_, 2025. [[pdf](https://arxiv.org/pdf/2509.14430)] (_Under Review_)

1. **Yufeng Yang**, Ashutosh Pandey, and DeLiang Wang, "Towards decoupling frontend enhancement and backend recognition in monaural robust ASR," _Computer Speech & Language_, 101821, 2026. [[pdf](https://www.sciencedirect.com/science/article/pii/S0885230825000464/pdfft?md5=efc37f9380f9b183a0e92200033e2047&pid=1-s2.0-S0885230825000464-main.pdf)]

1. **Yufeng Yang**, Desh Raj, Ju Lin, Niko Moritz, Junteng Jia, Gil Keren, Egor Lakomkin, Yiteng Huang, Jacob Donley, Jay Mahadeokar, and Ozlem Kalinli, "M-BEST-RQ: A multi-channel speech foundation model for smart glasses," in _Proc. IEEE ICASSP_, 2025, 5 pages. [[pdf](https://yfyangseu.github.io/files/icassp25_mbestrq.pdf)]

1. **Yufeng Yang**, Hassan Taherian, Vahid Ahmadi Kalkhorani, and DeLiang Wang, "Elevating robust ASR by decoupling multi-channel speaker separation and speech recognition," in _Proc. IEEE ICASSP_, 2025, 5 pages. [[pdf](https://yfyangseu.github.io/files/icassp25_elevating.pdf)]

1. **Yufeng Yang**, Ashutosh Pandey, and DeLiang Wang, "Time-domain speech enhancement for robust automatic speech recognition," in _Proc. Interspeech_, 2023, pp.4913-4917. [[pdf](https://www.isca-archive.org/interspeech_2023/yang23_interspeech.pdf)]
   

Other Publications
======
1. Heming Wang, **Yufeng Yang**, and DeLiang Wang, "A speech prediction model based on codec modeling and transformer decoding," _Computer Speech & Language_, 101892, 2026. [[pdf](https://www.sciencedirect.com/science/article/pii/S0885230825001172/pdfft?md5=bda7820c6e2a0a6174d89c3288774692&pid=1-s2.0-S0885230825001172-main.pdf)]

1. **Yufeng Yang**, Hassan Taherian, Vahid Ahmadi Kalkhorani, and DeLiang Wang, "Elevating robust multi-talker ASR by decoupling speaker separation and speech recognition," _arXiv:2503.17886_, 2025. [[pdf](https://arxiv.org/pdf/2503.17886)] (_Under Review_)

1. **Yufeng Yang**, Peidong Wang, and DeLiang Wang, "A Conformer based acoustic model for robust automatic speech recognition," _arXiv:2203.00725_, 2022. [[pdf](https://arxiv.org/pdf/2203.00725)]
   
1. Desmond Caulley, **Yufeng Yang**, and David Anderson, "EACELEB: an east Asian language speaking celebrity dataset for speaker recognition," _arXiv:2203.05333_, 2022. [[pdf](https://arxiv.org/pdf/2203.05333)]
   
1. Chuan Zhang<sup>\*</sup>, **Yufeng Yang**<sup>\*</sup>, Shunqing Zhang, Zaichen Zhang, and Xiaohu You, "Residual-based detections and unified architecture for massive MIMO uplink," _Journal of Signal Processing Systems_, vol. 91, no. 9, pp. 1039–1052, 2019. [[pdf](https://yfyangseu.github.io/files/2017-JSPS.pdf)]
   
1. **Yufeng Yang**, Wence Zhang, Jiejun Jin, Zaichen Zhang, Xiao You, and Chuan Zhang, "Efficient compressed Landweber detector for massive MIMO," in _Proc. IEEE SiPS_, 2018, pp. 65–70. [[pdf](https://yfyangseu.github.io/files/2018-SiPS.pdf)]
   
1. **Yufeng Yang**, Ye Xue, Xiaohu You, and Chuan Zhang, "An efficient conjugate residual detector for massive MIMO systems," in _Proc. IEEE SiPS_, 2017, pp. 1–6. [[pdf](https://yfyangseu.github.io/files/2017-SiPS.pdf)]


Academic Services
======
Reviewer for:
  * IEEE ICASSP
  * Interspeech
  * IEEE Signal Processing Letters
  * IEEE Transactions on Signal Processing
  * Computer Speech & Language
  * IEEE MWCAS
  * IEEE ISCAS

Volunteer for:
  * IEEE WCSP

Awards
======
* National Scholarship, Ministry of Education, China, 2015
* Meritorious Winner, Interdisciplinary Contest in Modeling (ICM), 2016
* Leike Scholarship, Southeast University, 2016

Acknowledgments
======
<div style="display: flex; gap: 10px; align-items: center;">
  <a href="https://www.seu.edu.cn/english/"><img src="https://yfyangseu.github.io/files/seu.png" alt="SEU" style='height:80px; object-fit: contain;'></a>
  <a href="https://www.gatech.edu/"><img src="https://yfyangseu.github.io/files/gatech.png" alt="GATech" style='height:80px; object-fit: contain;'></a>
  <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"><img src="https://yfyangseu.github.io/files/msra.png" alt="MSRA" style='height:80px; object-fit: contain;'></a>
  <a href="https://www.osu.edu/"><img src="https://yfyangseu.github.io/files/osu.png" alt="OSU" style='height:80px; object-fit: contain;'></a>
  <a href="https://www.merl.com/"><img src="https://yfyangseu.github.io/files/merl.jpg" alt="MERL" style='height:80px; object-fit: contain;'></a>
  <a href="https://ai.meta.com"><img src="https://yfyangseu.github.io/files/meta_s.png" alt="Meta" style='height:80px; object-fit: contain;'></a>
</div>

